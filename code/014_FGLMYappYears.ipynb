{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4ef5cc",
   "metadata": {},
   "source": [
    "**Oliver Seager<br>\n",
    "o.j.seager@lse.ac.uk<br>\n",
    "Python 3.9.7**\n",
    "\n",
    "**Created:** 07/05/2023 <br>\n",
    "**Last Modified:** 23/06/2023\n",
    "\n",
    "This script extracts application years from the individual OCRs of 1926-1975 patents from Fleming, Greene, Li, Marx and Yao (2019).\n",
    "\n",
    "**Infiles**: <br>\n",
    "- ***xxxxxxx.txt*; x in {0,1,...,9}** - 1,653,786 individual OCRs of 1926-1975 patents, each of a single patent with number *xxxxxxx*, from Fleming, Greene, Li, Marx and Yao (2019).\n",
    "\n",
    "**Outfiles**: <br>\n",
    "- **014_FGLMY2675appYears.dta** - USPTO patents from 1926-1975 with their application dates, as inferred from the Fleming, Greene, Li, Marx and Yao (2019) OCR.\n",
    "\n",
    "**External Packages**\n",
    "- `numpy` by Travis Oliphant\n",
    "- `pandas` by Wes McKinney"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a29c7",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Set Directory Shorthands\n",
    "\n",
    "subsample_dir = \"C:\\\\Users\\\\Ollie\\\\Dropbox\\\\State and innovation\\\\orig\\\\Fleming\\\\uspto.1926-1975\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2e157",
   "metadata": {},
   "source": [
    "### Get A List of the File Names for All Patents\n",
    "\n",
    "Each patent is an individual file which can be read as a single-line *.txt*. We get the list of file names here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPatents = os.listdir(subsample_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1eaff",
   "metadata": {},
   "source": [
    "### Initiate the DataFrame for Export\n",
    "\n",
    "This is what we'll put out to the final *.dta*. Variables...\n",
    "- **patent_id** is just the USPTO patent number\n",
    "- **appDate** is the year in which the application is filed according to the parse\n",
    "- **foundFiled** is an indicator for whether or not the word \"Filed\" was found in the patent. This is used, where possible, to locate the 4-character sequence of numbers that constitutes application year, which (if OCRing is correct) will appear shortly afterwards. This indicator generally will, if 0, indicate a shoddy OCR and encourage scepticism in using the application year found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"patent_id\", \"appDate\", \"foundFiled\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6291b",
   "metadata": {},
   "source": [
    "### Function for Putting Commas in Numbers\n",
    "\n",
    "Borrowed from code I've written elsewhere. Just used for the time update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commafy(x):\n",
    "    ## Put Commas into the Pre-decmial portion of the number ##\n",
    "    xIntFloor = int(np.floor(x)) # 1.234 will return 1\n",
    "    str_xIntFloor = str(xIntFloor) # Get string version of intege\n",
    "    len_str = len(str_xIntFloor) # Length of integer in characters\n",
    "    nr_commas = int(np.floor((len_str - 1)/3)) # Gets number of commas required\n",
    "    if nr_commas > 0:\n",
    "        strList = [] # Used to store maxIntFloor 3 character strings that compose the number\n",
    "        for i in range(nr_commas):\n",
    "            if i == 0:\n",
    "                strList = strList + [str_xIntFloor[-3:]] # For the first iteration, we just take the last three characters\n",
    "            else:\n",
    "                subStrEnd = (i)*-3 # Where the iteration's substring of str_xIntFloor will start (negative indexIntFloor) \n",
    "                subStrStart = (i + 1)*-3 # Where the iteration's substring of str_xIntFloor will end (negative indexIntFloor)\n",
    "                strList = strList + [str_xIntFloor[subStrStart:subStrEnd]] # Append three characters to list\n",
    "        strList = strList + [str_xIntFloor[:(-3*nr_commas)]] # Finally, add the characters that precede the first comma\n",
    "        strList.reverse() # Previous to this, the string \"12345678\" will produce list [\"678\",\"345\",\"12\"].\n",
    "        comma_xIntFloor = \",\".join(strList) # Join the list by commas\n",
    "    else: # If no commas are required, we just return the \n",
    "        comma_xIntFloor = str_xIntFloor\n",
    "    ## Add on Decimals if Needed ##\n",
    "    if x != xIntFloor:\n",
    "        xDecStr = str(x).split(\".\")[1] # Extracts the portion after the decimal place\n",
    "        comma_x = comma_xIntFloor + \".\" + xDecStr\n",
    "    else:\n",
    "        comma_x = comma_xIntFloor\n",
    "    return comma_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36933961",
   "metadata": {},
   "source": [
    "### Parse Patent Documents\n",
    "\n",
    "This loops through each patent, taking the first four character sequence of numbers \\[after the word \"Filed\", if found\\] as the application year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiations ##\n",
    "\n",
    "sub_df = pd.DataFrame(columns = [\"patent_id\", \"appDate\", \"foundFiled\"]) # We generate a new carrier DataFrame every 10,000 \n",
    "                                                                       # observations, as time taken to append a single row\n",
    "                                                                      # to a DataFrame is increasing in the length of the\n",
    "                                                                     # DataFrame\n",
    "\n",
    "i = 0 # Just a simple counter\n",
    "\n",
    "length = len(allPatents) # The total number of patents to be parsed\n",
    "\n",
    "time1 = time() # Initiate the time\n",
    "\n",
    "for patent in allPatents: # Iterates through all patents\n",
    "        \n",
    "    with open(subsample_dir + patent) as f: # Opens the patent's file as *.txt*\n",
    "        \n",
    "        ocr = f.readlines()[0] # Gets the string that constitutes the whole file\n",
    "        \n",
    "        ocrUpper = ocr.replace(\" \", \"\").upper() # Gets characters to upper case and removes spaces for ease of parsing\n",
    "        \n",
    "        foundFiled = (ocrUpper.find(\"FILED\") > -1) # Indicates whether the word \"Filed\" is found\n",
    "        \n",
    "        ocrTrimmed = ocrUpper[(ocrUpper.find(\"FILED\") + 1 + 4*foundFiled):] # Isolates string after the word \"FILED\"\n",
    "                                                                           # appears (if it appears)\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            appDate = re.search(\"\\d{4}\", ocrTrimmed).group(0) # Try to find 4-character sequence of numbers\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            appDate = 0 # Return year 0 if no 4-character sequence of numbers found\n",
    "        \n",
    "        appendDict = {\n",
    "            \"patent_id\":patent[:-4], # the [:-4] removes the \".txt\" from the filename, leaving just the patent number\n",
    "            \"appDate\":appDate, \n",
    "            \"foundFiled\":foundFiled\n",
    "        }\n",
    "        \n",
    "        sub_df = sub_df.append(appendDict, ignore_index = True) # Append data to the sub DataFrame\n",
    "        \n",
    "        i = i + 1 # Update the counter\n",
    "        \n",
    "        if i % 10000 == 0: # Executes every 10,000 patents\n",
    "            \n",
    "            df = pd.concat([df, sub_df]) # Adds the DataFrame containing the last 10,000 patents to the main DataFrame\n",
    "            \n",
    "            sub_df = pd.DataFrame(columns = [\"patent_id\", \"appDate\", \"foundFiled\"]) # Initiates a new DataFrame\n",
    "            \n",
    "            time2 = time() # Time after 10,000\n",
    "            \n",
    "            last10k = time2 - time1 # Time taken for the last 10,000, in seconds\n",
    "            \n",
    "            m = int(np.floor(last10k/60)) # Minutes digit(s)\n",
    "            \n",
    "            s = int(last10k - np.floor(last10k/60)*60) # Second digit(s)\n",
    "            \n",
    "            print(f\"{commafy(i)} of {commafy(length)} patents complete\")\n",
    "            \n",
    "            print(f\"Last 10,000 patents took {m}m{s}s\")\n",
    "            \n",
    "            time1 = time() # Restart the clock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6ed2e",
   "metadata": {},
   "source": [
    "### Export to *.csv*\n",
    "\n",
    "Pandas has an easy time reading *.dta* but is sometimes stubborn about exporting to it, so in the name of saving time we export to *.csv*, reimport, and export to Stata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1395b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv\n",
    "\n",
    "df.to_csv(\"C:\\\\Users\\\\Ollie\\\\Dropbox\\\\State and innovation\\\\data\\\\Fleming\\\\appYears.csv\")\n",
    "\n",
    "# Import from .csv\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Ollie\\\\Dropbox\\\\State and innovation\\\\data\\\\Fleming\\\\appYears.csv\").drop(\n",
    "    columns = \"Unnamed: 0\").set_index(\"patent_id\")\n",
    "\n",
    "# Export to .dta\n",
    "\n",
    "df.to_stata(\"C:\\\\Users\\\\Ollie\\\\Dropbox\\\\State and innovation\\\\data\\\\014_FGLMY2675appYears.dta\")\n",
    "\n",
    "# Erase .csv file\n",
    "\n",
    "os.remove(\"C:\\\\Users\\\\Ollie\\\\Dropbox\\\\State and innovation\\\\data\\\\Fleming\\\\appYears.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
